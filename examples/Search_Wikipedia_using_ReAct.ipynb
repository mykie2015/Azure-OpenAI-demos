{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX-FA27MbYpQ"
      },
      "source": [
        "# Search Wikipedia using ReAct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk4Y-PKWc3MU"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb\"><img src=\"https://github.com/google-gemini/cookbook/blob/main/images/colab_logo_32px.png?raw=1\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdkuZY1IdRal"
      },
      "source": [
        "This notebook is a minimal implementation of [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) with the Google `gemini-2.0-flash` model. You'll use ReAct prompting to configure a model to search Wikipedia to find the answer to a user's question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSr-BK-5meRo"
      },
      "source": [
        "In this walkthrough, you will learn how to:\n",
        "\n",
        "\n",
        "1.   Set up your development environment and API access to use Gemini.\n",
        "2.   Use a ReAct few-shot prompt.\n",
        "3.   Use the newly prompted model for multi-turn conversations (chat).\n",
        "4.   Connect the model to the **Wikipedia API**.\n",
        "5.  Have conversations with the model (try asking it questions like \"how tall is the Eiffel Tower?\") and watch it search Wikipedia.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce4xbIDDXP7L"
      },
      "source": [
        "> Note: The non-source code materials on this page are licensed under Creative Commons - Attribution-ShareAlike CC-BY-SA 4.0, https://creativecommons.org/licenses/by-sa/4.0/legalcode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSkx3VHr3WYb"
      },
      "source": [
        "### Background\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqoT0ojAcV9P"
      },
      "source": [
        "[ReAct](https://arxiv.org/abs/2210.03629) is a prompting method which allows language models to create a trace of their thinking processes and the steps required to answer a user's questions. This improves human interpretability and trustworthiness. ReAct prompted models generate Thought-Action-Observation triplets for every iteration, as you'll soon see. Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVvxnBG-thZG"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Twc_XZ7h7Bb4"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7oZwkgQpfrLl",
        "outputId": "1c4f6e39-20e2-42af-bfde-6c62e6e0703d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVWIqdtbffau"
      },
      "source": [
        "Note: The [`wikipedia` package](https://pypi.org/project/wikipedia/) notes that it was \"designed for ease of use and simplicity, not for advanced use\", and that production or heavy use should instead \"use [Pywikipediabot](http://www.mediawiki.org/wiki/Manual:Pywikipediabot) or one of the other more advanced [Python MediaWiki API wrappers](http://en.wikipedia.org/wiki/Wikipedia:Creating_a_bot#Python)\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Jz5HOLy47VX0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "import wikipedia\n",
        "from wikipedia.exceptions import DisambiguationError, PageError\n",
        "\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAvjxTybuWw-"
      },
      "source": [
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JAzIedGr9PdN"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqkwp87FumIp"
      },
      "source": [
        "## The ReAct prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLv9Kuuu5Ffs"
      },
      "source": [
        "The prompts used in the paper are available at [https://github.com/ysymyth/ReAct/tree/master/prompts](https://github.com/ysymyth/ReAct/tree/master/prompts)\n",
        "\n",
        "Here, you will be working with the following ReAct prompt with a few minor adjustments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ed55c29a1d"
      },
      "source": [
        "> Note: The prompt and in-context examples used here are borrowed from [https://github.com/ysymyth/ReAct](https://github.com/ysymyth/ReAct) which is published under a [MIT license](https://opensource.org/licenses/MIT)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g8klL8df4iXe"
      },
      "outputs": [],
      "source": [
        "model_instructions = \"\"\"Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, Observation is understanding relevant information from an Action's output and Action can be of three types:\n",
        "(1) <search>entity</search>, which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search and you can try to search the information from those topics.\n",
        "(2) <lookup>keyword</lookup>, which returns the next sentence containing keyword in the current context. This only does exact matches, so keep your searches short.\n",
        "(3) <finish>answer</finish>, which returns the answer and finishes the task.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw52CHAG0aRr"
      },
      "source": [
        "### Few-shot prompting to enable in-context learning with Gemini\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jhaD4ChNv6M"
      },
      "source": [
        "While large language models show good understanding of the instructions they are prompted with, they still may perform poorly on complex tasks in a zero-shot setting. Hence, you will now provide a few examples along with your prompt to steer the model's output according to your needs. This in-context learning improves the model's performance significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tZ7vezr02qv0"
      },
      "outputs": [],
      "source": [
        "examples = \"\"\"\n",
        "Here are some examples.\n",
        "\n",
        "Question\n",
        "What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n",
        "\n",
        "Thought 1\n",
        "I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n",
        "\n",
        "Action 1\n",
        "<search>Colorado orogeny</search>\n",
        "\n",
        "Observation 1\n",
        "The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n",
        "\n",
        "Thought 2\n",
        "It does not mention the eastern sector. So I need to look up eastern sector.\n",
        "\n",
        "Action 2\n",
        "<lookup>eastern sector</lookup>\n",
        "\n",
        "Observation 2\n",
        "The eastern sector extends into the High Plains and is called the Central Plains orogeny.\n",
        "\n",
        "Thought 3\n",
        "The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n",
        "\n",
        "Action 3\n",
        "<search>High Plains</search>\n",
        "\n",
        "Observation 3\n",
        "High Plains refers to one of two distinct land regions\n",
        "\n",
        "Thought 4\n",
        "I need to instead search High Plains (United States).\n",
        "\n",
        "Action 4\n",
        "<search>High Plains (United States)</search>\n",
        "\n",
        "Observation 4\n",
        "The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130m).\n",
        "\n",
        "Thought 5\n",
        "High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n",
        "\n",
        "Action 5\n",
        "<finish>1,800 to 7,000 ft</finish>\n",
        "\n",
        "Question\n",
        "Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
        "\n",
        "Thought 1\n",
        "The question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n",
        "\n",
        "Action 1\n",
        "<search>Milhouse</search>\n",
        "\n",
        "Observation 1\n",
        "Milhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n",
        "\n",
        "Thought 2\n",
        "The paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n",
        "\n",
        "Action 2\n",
        "<lookup>named after</lookup>\n",
        "\n",
        "Observation 2\n",
        "Milhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n",
        "\n",
        "Thought 3\n",
        "Milhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n",
        "\n",
        "Action 3\n",
        "<finish>Richard Nixon</finish>\n",
        "\n",
        "Question\n",
        "Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\n",
        "\n",
        "Thought 1\n",
        "I need to search Adam Clayton Powell and The Saimaa Gesture, and find which documentary is about Finnish rock groups.\n",
        "\n",
        "Action 1\n",
        "<search>Adam Clayton Powell</search>\n",
        "\n",
        "Observation 1\n",
        "Could not find [Adam Clayton Powell]. Similar: [’Adam Clayton Powell III’, ’Seventh Avenue (Manhattan)’, ’Adam Clayton Powell Jr. State Office Building’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell (film)’, ’Giancarlo Esposito’].\n",
        "\n",
        "Thought 2\n",
        "To find the documentary, I can search Adam Clayton Powell (film).\n",
        "\n",
        "Action 2\n",
        "<search>Adam Clayton Powell (film)</search>\n",
        "\n",
        "Observation 2\n",
        "Adam Clayton Powell is a 1989 American documentary film directed by Richard Kilberg. The film is about the rise and fall of influential African-American politician Adam Clayton Powell Jr.[3][4] It was later aired as part of the PBS series The American Experience.\n",
        "\n",
        "Thought 3\n",
        "Adam Clayton Powell (film) is a documentary about an African-American politician, not Finnish rock groups. So the documentary about Finnish rock groups must instead be The Saimaa Gesture.\n",
        "\n",
        "Action 3\n",
        "<finish>The Saimaa Gesture</finish>\n",
        "\n",
        "Question\n",
        "What profession does Nicholas Ray and Elia Kazan have in common?\n",
        "\n",
        "Thought 1\n",
        "I need to search Nicholas Ray and Elia Kazan, find their professions, then find the profession they have in common.\n",
        "\n",
        "Action 1\n",
        "<search>Nicholas Ray</search>\n",
        "\n",
        "Observation 1\n",
        "Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\n",
        "\n",
        "Thought 2\n",
        "Professions of Nicholas Ray are director, screenwriter, and actor. I need to search Elia Kazan next and find his professions.\n",
        "\n",
        "Action 2\n",
        "<search>Elia Kazan</search>\n",
        "\n",
        "Observation 2\n",
        "Elia Kazan was an American film and theatre director, producer, screenwriter and actor.\n",
        "\n",
        "Thought 3\n",
        "Professions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.\n",
        "\n",
        "Action 3\n",
        "<finish>director, screenwriter, actor</finish>\n",
        "\n",
        "Question\n",
        "Which magazine was started first Arthur’s Magazine or First for Women?\n",
        "\n",
        "Thought 1\n",
        "I need to search Arthur’s Magazine and First for Women, and find which was started first.\n",
        "\n",
        "Action 1\n",
        "<search>Arthur’s Magazine</search>\n",
        "\n",
        "Observation 1\n",
        "Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n",
        "\n",
        "Thought 2\n",
        "Arthur’s Magazine was started in 1844. I need to search First for Women next.\n",
        "\n",
        "Action 2\n",
        "<search>First for Women</search>\n",
        "\n",
        "Observation 2\n",
        "First for Women is a woman’s magazine published by Bauer Media Group in the USA.[1] The magazine was started in 1989.\n",
        "\n",
        "Thought 3\n",
        "First for Women was started in 1989. 1844 (Arthur’s Magazine) < 1989 (First for Women), so Arthur’s Magazine was started first.\n",
        "\n",
        "Action 3\n",
        "<finish>Arthur’s Magazine</finish>\n",
        "\n",
        "Question\n",
        "Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
        "\n",
        "Thought 1\n",
        "I need to search Pavel Urysohn and Leonid Levin, find their types of work, then find if they are the same.\n",
        "\n",
        "Action 1\n",
        "<search>Pavel Urysohn</search>\n",
        "\n",
        "Observation 1\n",
        "Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician who is best known for his contributions in dimension theory.\n",
        "\n",
        "Thought 2\n",
        "Pavel Urysohn is a mathematician. I need to search Leonid Levin next and find its type of work.\n",
        "\n",
        "Action 2\n",
        "<search>Leonid Levin</search>\n",
        "\n",
        "Observation 2\n",
        "Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.\n",
        "\n",
        "Thought 3\n",
        "Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.\n",
        "\n",
        "Action 3\n",
        "<finish>yes</finish>\n",
        "\n",
        "Question\n",
        "{question}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeCImqiN3WiQ"
      },
      "source": [
        "Copy the instructions along with examples in a file called `model_instructions.txt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyTfAdpk26oB"
      },
      "outputs": [],
      "source": [
        "ReAct_prompt = model_instructions + examples\n",
        "with open('model_instructions.txt', 'w') as f:\n",
        "  f.write(ReAct_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is8BIVQP3u95"
      },
      "source": [
        "## The Gemini-ReAct pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqEwKVDgM1MF"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4M3lxEoM3k0"
      },
      "source": [
        "You will now build an end-to-end pipeline to facilitate multi-turn chat with the ReAct-prompted Gemini model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vssDZcroN-Ob"
      },
      "outputs": [],
      "source": [
        "class ReAct:\n",
        "  def __init__(self, model: str, ReAct_prompt: str | os.PathLike):\n",
        "    \"\"\"Prepares Gemini to follow a `Few-shot ReAct prompt` by imitating\n",
        "    `function calling` technique to generate both reasoning traces and\n",
        "    task-specific actions in an interleaved manner.\n",
        "\n",
        "    Args:\n",
        "        model: name to the model.\n",
        "        ReAct_prompt: ReAct prompt OR path to the ReAct prompt.\n",
        "    \"\"\"\n",
        "    self.model = genai.GenerativeModel(model)\n",
        "    self.chat = self.model.start_chat(history=[])\n",
        "    self.should_continue_prompting = True\n",
        "    self._search_history: list[str] = []\n",
        "    self._search_urls: list[str] = []\n",
        "\n",
        "    try:\n",
        "      # try to read the file\n",
        "      with open(ReAct_prompt, 'r') as f:\n",
        "        self._prompt = f.read()\n",
        "    except FileNotFoundError:\n",
        "      # assume that the parameter represents prompt itself rather than path to the prompt file.\n",
        "      self._prompt = ReAct_prompt\n",
        "\n",
        "  @property\n",
        "  def prompt(self):\n",
        "    return self._prompt\n",
        "\n",
        "  @classmethod\n",
        "  def add_method(cls, func):\n",
        "    setattr(cls, func.__name__, func)\n",
        "\n",
        "  @staticmethod\n",
        "  def clean(text: str):\n",
        "    \"\"\"Helper function for responses.\"\"\"\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKfThpmhMZYZ"
      },
      "source": [
        "### Define tools\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnvZ2jqdRHE1"
      },
      "source": [
        "As instructed by the prompt, the model will be generating **Thought-Action-Observation** traces, where every **Action** trace could be one of the following tokens:\n",
        "\n",
        "\n",
        "1.   </search/> : Perform a Wikipedia search via external API.\n",
        "2.   </lookup/> : Lookup for specific information on a page with the Wikipedia API.\n",
        "3.   </finish/> : Stop the execution of the model and return the answer.\n",
        "\n",
        "If the model encounters any of these tokens, the model should make use of the `tools` made available to the model. This understanding of the model to leverage acquired toolsets to collect information from the external world is often referred to as **function calling**. Therefore, the next goal is to imitate this function calling technique in order to allow ReAct prompted Gemini model to access the external groundtruth.\n",
        "\n",
        "The Gemini API supports function calling and you could use this feature to set up your tools. However, for this tutorial, you will learn to simulate it using `stop_sequences` parameter.\n",
        "\n",
        "\n",
        "Define the tools:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysHN4y4FPlJZ"
      },
      "source": [
        "#### Search\n",
        "Define a method to perform Wikipedia searches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yCRB4g4BNzak"
      },
      "outputs": [],
      "source": [
        "@ReAct.add_method\n",
        "def search(self, query: str):\n",
        "    \"\"\"Perfoms search on `query` via Wikipedia api and returns its summary.\n",
        "\n",
        "    Args:\n",
        "        query: Search parameter to query the Wikipedia API with.\n",
        "\n",
        "    Returns:\n",
        "        observation: Summary of Wikipedia search for `query` if found else\n",
        "        similar search results.\n",
        "    \"\"\"\n",
        "    observation = None\n",
        "    query = query.strip()\n",
        "    try:\n",
        "      # try to get the summary for requested `query` from the Wikipedia\n",
        "      observation = wikipedia.summary(query, sentences=4, auto_suggest=False)\n",
        "      wiki_url = wikipedia.page(query, auto_suggest=False).url\n",
        "      observation = self.clean(observation)\n",
        "\n",
        "      # if successful, return the first 2-3 sentences from the summary as model's context\n",
        "      observation = self.model.generate_content(f'Retun the first 2 or 3 \\\n",
        "      sentences from the following text: {observation}')\n",
        "      observation = observation.text\n",
        "\n",
        "      # keep track of the model's search history\n",
        "      self._search_history.append(query)\n",
        "      self._search_urls.append(wiki_url)\n",
        "      print(f\"Information Source: {wiki_url}\")\n",
        "\n",
        "    # if the page is ambiguous/does not exist, return similar search phrases for model's context\n",
        "    except (DisambiguationError, PageError) as e:\n",
        "      observation = f'Could not find [\"{query}\"].'\n",
        "      # get a list of similar search topics\n",
        "      search_results = wikipedia.search(query)\n",
        "      observation += f' Similar: {search_results}. You should search for one of those instead.'\n",
        "\n",
        "    return observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fUbHUsPyoF"
      },
      "source": [
        "#### Lookup\n",
        "Look for a specific phrase on the Wikipedia page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_F4kAF77O0E_"
      },
      "outputs": [],
      "source": [
        "@ReAct.add_method\n",
        "def lookup(self, phrase: str, context_length=200):\n",
        "    \"\"\"Searches for the `phrase` in the lastest Wikipedia search page\n",
        "    and returns number of sentences which is controlled by the\n",
        "    `context_length` parameter.\n",
        "\n",
        "    Args:\n",
        "        phrase: Lookup phrase to search for within a page. Generally\n",
        "        attributes to some specification of any topic.\n",
        "\n",
        "        context_length: Number of words to consider\n",
        "        while looking for the answer.\n",
        "\n",
        "    Returns:\n",
        "        result: Context related to the `phrase` within the page.\n",
        "    \"\"\"\n",
        "    # get the last searched Wikipedia page and find `phrase` in it.\n",
        "    page = wikipedia.page(self._search_history[-1], auto_suggest=False)\n",
        "    page = page.content\n",
        "    page = self.clean(page)\n",
        "    start_index = page.find(phrase)\n",
        "\n",
        "    # extract sentences considering the context length defined\n",
        "    result = page[max(0, start_index - context_length):start_index+len(phrase)+context_length]\n",
        "    print(f\"Information Source: {self._search_urls[-1]}\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc4mq2qlQCnE"
      },
      "source": [
        "#### Finish\n",
        "Instruct the pipline to terminate its execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0Wxpx8COPak_"
      },
      "outputs": [],
      "source": [
        "@ReAct.add_method\n",
        "def finish(self, _):\n",
        "  \"\"\"Finishes the conversation on encountering <finish> token by\n",
        "  setting the `self.should_continue_prompting` flag to `False`.\n",
        "  \"\"\"\n",
        "  self.should_continue_prompting = False\n",
        "  print(f\"Information Sources: {self._search_urls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Tl6W98Zhut"
      },
      "source": [
        "### Stop tokens and function calling imitation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VnX9zpBcdA0"
      },
      "source": [
        "Now that you are all set with function definitions, the next step is to instruct the model to interrupt its execution upon encountering any of the action tokens. You will make use of the `stop_sequences` parameter from [`genai.GenerativeModel.GenerationConfig`](https://ai.google.dev/api/python/google/generativeai/GenerationConfig) class to instruct the model when to stop. Upon encountering an action token, the pipeline will simply extract what specific token from the `stop_sequences` argument terminated the model's execution, and then call the appropriate **tool** (function).\n",
        "\n",
        "The function's response will be added to model's chat history for continuing the context link."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vnQom1aQOsK8"
      },
      "outputs": [],
      "source": [
        "@ReAct.add_method\n",
        "def __call__(self, user_question, max_calls: int=8, **generation_kwargs):\n",
        "  \"\"\"Starts multi-turn conversation with the chat models with function calling\n",
        "\n",
        "  Args:\n",
        "      max_calls: max calls made to the model to get the final answer.\n",
        "\n",
        "      generation_kwargs: Same as genai.GenerativeModel.GenerationConfig\n",
        "              candidate_count: (int | None) = None,\n",
        "              stop_sequences: (Iterable[str] | None) = None,\n",
        "              max_output_tokens: (int | None) = None,\n",
        "              temperature: (float | None) = None,\n",
        "              top_p: (float | None) = None,\n",
        "              top_k: (int | None) = None\n",
        "\n",
        "  Raises:\n",
        "      AssertionError: if max_calls is not between 1 and 8\n",
        "  \"\"\"\n",
        "\n",
        "  # hyperparameter fine-tuned according to the paper\n",
        "  assert 0 < max_calls <= 8, \"max_calls must be between 1 and 8\"\n",
        "\n",
        "  if len(self.chat.history) == 0:\n",
        "    model_prompt = self.prompt.format(question=user_question)\n",
        "  else:\n",
        "    model_prompt = user_question\n",
        "\n",
        "  # stop_sequences for the model to immitate function calling\n",
        "  callable_entities = ['</search>', '</lookup>', '</finish>']\n",
        "\n",
        "  generation_kwargs.update({'stop_sequences': callable_entities})\n",
        "\n",
        "  self.should_continue_prompting = True\n",
        "  for idx in range(max_calls):\n",
        "\n",
        "    self.response = self.chat.send_message(content=[model_prompt],\n",
        "              generation_config=generation_kwargs, stream=False)\n",
        "\n",
        "    for chunk in self.response:\n",
        "      print(chunk.text, end=' ')\n",
        "\n",
        "    response_cmd = self.chat.history[-1].parts[-1].text\n",
        "\n",
        "    try:\n",
        "      # regex to extract <function name writen in between angular brackets>\n",
        "      cmd = re.findall(r'<(.*)>', response_cmd)[-1]\n",
        "      print(f'</{cmd}>')\n",
        "      # regex to extract param\n",
        "      query = response_cmd.split(f'<{cmd}>')[-1].strip()\n",
        "      # call to appropriate function\n",
        "      observation = self.__getattribute__(cmd)(query)\n",
        "\n",
        "      if not self.should_continue_prompting:\n",
        "        break\n",
        "\n",
        "      stream_message = f\"\\nObservation {idx + 1}\\n{observation}\"\n",
        "      print(stream_message)\n",
        "      # send function's output as user's response\n",
        "      model_prompt = f\"<{cmd}>{query}</{cmd}>'s Output: {stream_message}\"\n",
        "\n",
        "    except (IndexError, AttributeError) as e:\n",
        "      model_prompt = \"Please try to generate thought-action-observation traces \\\n",
        "      as instructed by the prompt.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtndhebkhW62"
      },
      "source": [
        "### Test ReAct prompted Gemini model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h_KWkXWwfZ5h",
        "outputId": "3ad87b2c-900b-4c18-bb31-8fb8adda9e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, I'm ready. Please provide the content of `model_instructions.txt`. I will analyze it and use it to guide my responses. I will do my best to follow the instructions within the file.\n",
            " Okay, I understand. I will now attempt to generate responses in the Thought-Action-Observation format, as if I were following instructions from a prompt that requires it.\n",
            "\n",
            "To do this effectively, I need a **task or question** to respond to. Please provide me with the task or question you want me to address using the Thought-Action-Observation format.\n",
            "\n",
            "For example, you could ask me:\n",
            "\n",
            "*   \"What is the capital of France?\"\n",
            "*   \"Summarize the plot of Hamlet.\"\n",
            "*   \"Write a short story about a cat who can talk.\"\n",
            "\n",
            "Once you give me a task, I will respond in the following structure:\n",
            "\n",
            "**Thought:** *My internal reasoning and planning to address the task.*\n",
            "**Action:** *The specific action I will take (e.g., searching for information, writing code, generating text).*\n",
            "**Observation:** *The result of my action (e.g., the information I found, the code I generated, the text I produced).*\n",
            "**Final Answer:** *My final answer to the task, based on my observations.*\n",
            "\n",
            "I'm ready when you are!\n",
            " You've already given me the instruction to generate Thought-Action-Observation traces. I need a *task* to apply that instruction to.\n",
            "\n",
            "Please provide the task or question you want me to answer using the Thought-Action-Observation format. I can't generate a trace without knowing what I'm supposed to be doing!\n",
            " I understand that you want me to generate Thought-Action-Observation traces. I am repeating this to confirm I understand. However, I still need a **task** to perform.\n",
            "\n",
            "Think of it like this: you've told me *how* to do something (use Thought-Action-Observation), but you haven't told me *what* to do.\n",
            "\n",
            "Please give me a question, a problem to solve, or a task to complete. For example:\n",
            "\n",
            "*   \"Explain the concept of recursion.\"\n",
            "*   \"Translate 'Hello, world!' into Spanish.\"\n",
            "*   \"Write a haiku about autumn.\"\n",
            "\n",
            "Once you provide the task, I will generate the Thought-Action-Observation trace.\n",
            " I am still waiting for a task. I understand the instruction: \"Please try to generate thought-action-observation traces as instructed by the prompt.\"  The problem is, *there is no prompt* other than that instruction. The instruction tells me *how* to respond, but not *what* to respond *to*.\n",
            "\n",
            "I need a question, a request, a problem, *something* to which I can apply the Thought-Action-Observation process.\n",
            "\n",
            "Please provide the task.\n",
            " Okay, I'm going to try a different approach. Since you're repeatedly asking me to generate Thought-Action-Observation traces *without providing a task*, I'm going to *assume* the task is to demonstrate the Thought-Action-Observation process itself.\n",
            "\n",
            "**Thought:** I need to demonstrate the Thought-Action-Observation process. I will create a simple example where I \"think\" about a question, \"act\" by answering it, and then \"observe\" the result.\n",
            "\n",
            "**Action:** I will answer the question: \"What is 2 + 2?\"\n",
            "\n",
            "**Observation:** 2 + 2 = 4\n",
            "\n",
            "**Final Answer:** 4\n",
            "\n",
            "I hope this demonstrates the Thought-Action-Observation process.  However, to be truly useful, I need you to provide a *different* task.  Please give me a specific question or problem to solve.\n",
            " I understand. You want me to generate Thought-Action-Observation traces. I am still waiting for the specific task or question you want me to address. Since you are not providing one, I will generate another example based on the *assumption* that you want me to demonstrate the process itself.\n",
            "\n",
            "**Thought:** Since the user is repeatedly asking for Thought-Action-Observation traces without providing a task, I will demonstrate the process by explaining why I need a task.\n",
            "\n",
            "**Action:** I will explain why I need a task to generate a meaningful Thought-Action-Observation trace.\n",
            "\n",
            "**Observation:** A Thought-Action-Observation trace is a structured way of problem-solving. It requires a specific problem or question to initiate the \"thought\" process. Without a task, the \"thought\" is aimless, the \"action\" is arbitrary, and the \"observation\" is meaningless. It's like asking me to run a program without telling me what the program is supposed to do.\n",
            "\n",
            "**Final Answer:** I need a specific task or question to generate a useful Thought-Action-Observation trace. Please provide one.\n",
            " I am programmed to be helpful and follow instructions. I understand you want me to generate Thought-Action-Observation traces. However, I cannot fulfill this request meaningfully without a specific task or question.\n",
            "\n",
            "To reiterate, a Thought-Action-Observation trace requires:\n",
            "\n",
            "1.  **A Task:** A problem to solve, a question to answer, or a goal to achieve.\n",
            "2.  **Thought:** My internal reasoning and planning to address the task.\n",
            "3.  **Action:** The specific action I will take (e.g., searching for information, writing code, generating text).\n",
            "4.  **Observation:** The result of my action (e.g., the information I found, the code I generated, the text I produced).\n",
            "5.  **Final Answer:** My final answer to the task, based on my observations.\n",
            "\n",
            "Since you are only providing the instruction (\"Please try to generate thought-action-observation traces as instructed by the prompt\") and not the task, I am unable to proceed.\n",
            "\n",
            "Please provide a task.\n",
            " "
          ]
        }
      ],
      "source": [
        "gemini_ReAct_chat = ReAct(model='gemini-2.0-flash', ReAct_prompt='model_instructions.txt')\n",
        "# Note: try different combinations of generational_config parameters for variational results\n",
        "gemini_ReAct_chat(\"What are the total of ages of the main trio from the new Percy Jackson and the Olympians TV series in real life?\", temperature=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIfeyyI6hoIE"
      },
      "source": [
        "Now, try asking the same question to `gemini-2.0-flash` model without the ReAct prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_NUXNbTuakSC",
        "outputId": "406cf618-4f82-4162-ffaa-d9fb5a13a736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, here's the breakdown of the actors' ages and the total:\\n\\n*   **Walker Scobell (Percy Jackson):** Born January 6, 2009, which makes him currently **15 years old** (as of November 2024).\\n\\n*   **Leah Sava Jeffries (Annabeth Chase):** Born September 25, 2011, which makes her currently **13 years old** (as of November 2024).\\n\\n*   **Aryan Simhadri (Grover Underwood):** Born June 6, 2006, which makes him currently **18 years old** (as of November 2024).\\n\\n**Total:** 15 + 13 + 18 = **46 years old**\\n\\nSo, the total age of the main trio is approximately **46 years old**.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "gemini_ReAct_chat.model.generate_content(\"What is the total of ages of the main trio from the new Percy Jackson and the Olympians TV series in real life?\").text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_ReAct_chat.model.generate_content(\"德约科维奇职业生涯以来澳网表现，以及2025这届表现\").text"
      ],
      "metadata": {
        "id": "kxBa4zUzUXdA",
        "outputId": "ef1ae06b-d6d9-421e-e406-b74a553fd435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-06 22:14:29.551 200 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 34543.74ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'诺瓦克·德约科维奇在澳大利亚网球公开赛上的表现堪称传奇，他是公开赛时代以来澳网男单夺冠次数最多的球员，因此也被誉为“澳网之王”。\\n\\n**德约科维奇澳网职业生涯总结：**\\n\\n*   **参赛次数：** 19次（截至2024年）\\n*   **总战绩：** 97胜9负（截至2024年）\\n*   **首次参赛：** 2005年\\n*   **首次夺冠：** 2008年\\n*   **夺冠次数：** 10次 (2008, 2011, 2012, 2013, 2015, 2016, 2019, 2020, 2021, 2023)\\n*   **亚军：** 1次 (2007年，负于费德勒)\\n*   **最长连胜纪录：** 41场（2019年至2024年，2022年因未接种疫苗被驱逐无法参赛，因此连胜中断，否则可能更长）\\n*   **未夺冠年份最佳战绩：** 四强（2010年）\\n\\n**德约科维奇澳网历年战绩：**\\n\\n| 年份 | 轮次    | 对手                                      | 比分          |\\n| ---- | ------- | ----------------------------------------- | ------------- |\\n| 2005 | 第一轮  | 马拉特·萨芬                                | 0-6, 2-6, 1-6 |\\n| 2006 | 第一轮  | 保罗·戈尔茨坦                             | 6-3, 6-2, 6-4 |\\n|      | 第二轮  | 阿梅尔·德利奇                             | 6-1, 6-2, 6-4 |\\n|      | 第三轮  | 吉列尔莫·加西亚-洛佩斯                     | 6-3, 6-7(3), 6-4, 7-6(3) |\\n|      | 第四轮  | 罗杰·费德勒                                | 2-6, 5-7, 3-6 |\\n| 2007 | 第一轮  | 尼古拉斯·马苏                             | 6-1, 6-1, 6-0 |\\n|      | 第二轮  | 菲利普·科尔施赖伯                         | 6-4, 6-3, 6-4 |\\n|      | 第三轮  | 丹·摩尔                                  | 6-4, 7-6(3), 6-1 |\\n|      | 第四轮  | 马迪·费什                                  | 6-4, 7-6(4), 6-4 |\\n|      | 1/4决赛 | 吉列尔莫·加西亚-洛佩斯                     | 6-3, 7-6(5), 4-6, 6-1 |\\n|      | 半决赛  | 罗杰·费德勒                                | 6-2, 7-5, 6-3 |\\n|      | **决赛** | **罗杰·费德勒**                            | **2-6, 5-7, 2-6** |\\n| 2008 | 第一轮  | 本杰明·贝克尔                             | 6-0, 6-0, 6-4 |\\n|      | 第二轮  | 西蒙尼·博莱利                             | 6-3, 6-4, 6-3 |\\n|      | 第三轮  | 萨姆·奎里                                  | 6-3, 6-1, 6-3 |\\n|      | 第四轮  | 莱顿·休伊特                                | 7-5, 6-3, 6-1 |\\n|      | 1/4决赛 | 大卫·费雷尔                                | 6-0, 6-3, 7-5 |\\n|      | 半决赛  | 罗杰·费德勒                                | 7-5, 6-3, 7-6(5) |\\n|      | **决赛** | **若-威尔弗里德·特松加**                     | **4-6, 6-4, 6-3, 7-6(2)** |\\n| 2009 | 第一轮  | 安德烈亚斯·塞皮                             | 6-2, 7-5, 7-6(3) |\\n|      | 第二轮  | 热雷米·查迪                                | 7-5, 6-1, 6-2 |\\n|      | 第三轮  | 阿梅尔·德利奇                             | 6-2, 4-6, 6-3, 7-6(4) |\\n|      | 第四轮  | 马科斯·巴格达蒂斯                           | 1-6, 6-7(1), 6-1, 6-3, 9-7 |\\n|      | 1/4决赛 | 安迪·罗迪克                                | 7-6(3), 4-6, 2-6, 6-2, 3-6 |\\n| 2010 | 第一轮  | 丹尼尔·埃文斯                             | 6-3, 6-1, 6-1 |\\n|      | 第二轮  | 马尔科·奇迪内里                             | 6-3, 7-5, 6-4 |\\n|      | 第三轮  | 伊戈尔·安德烈夫                             | 6-0, 6-3, 6-2 |\\n|      | 第四轮  | 莱顿·休伊特                                | 6-2, 6-4, 6-4 |\\n|      | 1/4决赛 | 若-威尔弗里德·特松加                     | 7-6(8), 6-7(5), 1-6, 6-3, 6-1 |\\n|      | 半决赛  | 罗杰·费德勒                                | 3-6, 6-2, 4-6, 6-7(3) |\\n| 2011 | 第一轮  | 马塞尔·格拉诺勒斯                           | 6-1, 6-3, 6-1 |\\n|      | 第二轮  | 伊万·多迪格                                | 7-5, 6-7(8), 6-0, 6-2 |\\n|      | 第三轮  | 维克托·特罗伊茨基                           | 6-2, 6-1, 6-4 |\\n|      | 第四轮  | 尼古拉斯·阿尔玛格罗                         | 6-3, 6-4, 6-0 |\\n|      | 1/4决赛 | 托马斯·伯蒂奇                             | 6-1, 7-6(5), 6-1 |\\n|      | 半决赛  | 罗杰·费德勒                                | 7-6(3), 7-5, 6-4 |\\n|      | **决赛** | **安迪·穆雷**                               | **6-4, 6-2, 6-3** |\\n| 2012 | 第一轮  | 保罗·洛伦齐                                | 6-2, 6-0, 6-0 |\\n|      | 第二轮  | 圣地亚哥·希拉尔多                           | 6-3, 6-2, 6-1 |\\n|      | 第三轮  | 尼古拉斯·马胡                               | 6-3, 6-2, 6-4 |\\n|      | 第四轮  | 莱顿·休伊特                                | 6-1, 6-3, 4-6, 6-3 |\\n|      | 1/4决赛 | 大卫·费雷尔                                | 6-4, 7-6(4), 6-1 |\\n|      | 半决赛  | 安迪·穆雷                                  | 6-3, 3-6, 6-7(4), 6-1, 7-5 |\\n|      | **决赛** | **拉斐尔·纳达尔**                           | **5-7, 6-4, 6-2, 6-7(5), 7-5** |\\n| 2013 | 第一轮  | 保罗·埃尔伯                                | 6-2, 6-4, 7-5 |\\n|      | 第二轮  | 瑞安·哈里森                                | 6-1, 6-2, 6-3 |\\n|      | 第三轮  | 拉德克·斯泰潘内克                           | 6-4, 6-3, 7-5 |\\n|      | 第四轮  | 斯坦·瓦林卡                                | 1-6, 7-5, 6-4, 6-7(5), 12-10 |\\n|      | 1/4决赛 | 托马斯·伯蒂奇                             | 6-1, 4-6, 6-1, 6-4 |\\n|      | 半决赛  | 大卫·费雷尔                                | 6-2, 6-2, 6-1 |\\n|      | **决赛** | **安迪·穆雷**                               | **6-7(2), 7-6(3), 6-3, 6-2** |\\n| 2014 | 1/4决赛 | 斯坦·瓦林卡                                | 6-2, 4-6, 2-6, 6-3, 7-9 |\\n| 2015 | 第一轮  | 阿尔亚·贝德内                               | 6-3, 6-2, 6-4 |\\n|      | 第二轮  | 安德烈·库兹涅佐夫                           | 6-0, 6-1, 6-4 |\\n|      | 第三轮  | 费尔南多·沃达斯科                           | 7-6(6), 6-3, 6-4 |\\n|      | 第四轮  | 吉勒·穆勒                                  | 6-4, 7-5, 7-5 |\\n|      | 1/4决赛 | 米洛斯·拉奥尼奇                             | 7-6(5), 6-4, 6-2 |\\n|      | 半决赛  | 斯坦·瓦林卡                                | 7-6(1), 3-6, 6-4, 4-6, 6-0 |\\n|      | **决赛** | **安迪·穆雷**                               | **7-6(5), 6-7(4), 6-3, 6-0** |\\n| 2016 | 第一轮  | 郑泫                                      | 6-3, 6-2, 6-4 |\\n|      | 第二轮  | 昆汀·哈里斯                                | 6-1, 6-2, 6-3 |\\n|      | 第三轮  | 安德烈亚斯·塞皮                             | 6-1, 7-5, 7-6(6) |\\n|      | 第四轮  | 吉尔·西蒙                                  | 6-3, 6-7(1), 6-4, 4-6, 6-3 |\\n|      | 1/4决赛 | 锦织圭                                    | 6-3, 6-2, 6-4 |\\n|      | 半决赛  | 罗杰·费德勒                                | 6-1, 6-2, 3-6, 6-3 |\\n|      | **决赛** | **安迪·穆雷**                               | **6-1, 7-5, 7-6(3)** |\\n| 2017 | 第二轮  | 丹尼斯·伊斯托明                             | 6-7(8), 7-5, 6-2, 6-7(5), 4-6 |\\n| 2018 | 第四轮  | 郑泫                                      | 6-7(4), 5-7, 6-7(3) |\\n| 2019 | 第一轮  | 米切尔·克鲁格                             | 6-3, 6-2, 6-2 |\\n|      | 第二轮  | 乔-维尔弗里德·特松加                         | 6-3, 7-5, 6-4 |\\n|      | 第三轮  | 丹尼斯·沙波瓦洛夫                           | 6-3, 6-4, 4-6, 6-0 |\\n|      | 第四轮  | 丹尼尔·梅德韦杰夫                           | 6-4, 6-7(5), 6-2, 6-3 |\\n|      | 1/4决赛 | 锦织圭                                    | 6-1, 4-1 (退赛)               |\\n|      | 半决赛  | 卢卡斯·普耶                                | 6-0, 6-2, 6-2 |\\n|      | **决赛** | **拉斐尔·纳达尔**                           | **6-3, 6-2, 6-3** |\\n| 2020 | 第一轮  | 扬-伦纳德·斯特鲁夫                           | 7-6(5), 6-2, 2-6, 6-1 |\\n|      | 第二轮  | 达藤太郎                                  | 6-1, 6-4, 6-2 |\\n|      | 第三轮  | 西冈良仁                                  | 6-3, 6-2, 6-2 |\\n|      | 第四轮  | 迭戈·施瓦茨曼                             | 6-3, 6-4, 6-4 |\\n|      | 1/4决赛 | 米洛斯·拉奥尼奇                             | 6-4, 6-3, 7-6(1) |\\n|      | 半决赛  | 罗杰·费德勒                                | 7-6(1), 6-4, 6-3 |\\n|      | **决赛** | **多米尼克·蒂姆**                           | **6-4, 4-6, 2-6, 6-3, 6-4** |\\n| 2021 | 第一轮  | 杰里米·查迪                                | 6-3, 6-1, 6-2 |\\n|      | 第二轮  | 蒂亚戈·蒙泰罗                             | 6-1, 6-4, 6-3 |\\n|      | 第三轮  | 泰勒·弗里茨                                | 7-6(1), 6-4, 3-6, 4-6, 6-2 |\\n|      | 第四轮  | 米洛斯·拉奥尼奇                             | 7-6(4), 4-6, 6-1, 6-4 |\\n|      | 1/4决赛 | 亚历山大·兹维列夫                           | 6-7(6), 6-2, 6-4, 7-6(6) |\\n|      | 半决赛  | 阿斯兰·卡拉采夫                             | 6-3, 6-4, 6-2 |\\n|      | **决赛** | **丹尼尔·梅德韦杰夫**                         | **7-5, 6-2, 6-2** |\\n| 2022 |  |  因未接种疫苗被驱逐，未能参赛                     |               |\\n| 2023 | 第一轮  | 罗伯托·卡巴列罗·巴埃纳                       | 6-3, 6-4, 7-6(4) |\\n|      | 第二轮  | 恩佐·库阿科                                | 6-1, 6-7(5), 6-2, 6-0 |\\n|      | 第三轮  | 格里戈尔·季米特洛夫                         | 7-6(7), 6-3, 6-4 |\\n|      | 第四轮  | 亚历克斯·德米纳尔                           | 6-2, 6-1, 6-2 |\\n|      | 1/4决赛 | 安德烈·鲁布列夫                             | 6-1, 6-2, 6-4 |\\n|      | 半决赛  | 汤米·保罗                                  | 7-5, 6-1, 6-2 |\\n|      | **决赛** | **西西帕斯**                                | **6-3, 7-6(4), 7-6(5)** |\\n| 2024 | 第一轮 | 迪诺·普里兹米奇 | 6-2, 6-7(5), 6-3, 6-4 |\\n|  | 第二轮 | 阿列克谢·波佩林 | 6-3, 6-2, 6-4 |\\n|  | 第三轮 | 托马斯·马丁·埃切韦里 | 6-3, 6-3, 7-6(2) |\\n|  | 第四轮 | 阿德里安·马纳里诺 | 6-0, 6-0, 6-3 |\\n|  | 1/4决赛 | 泰勒·弗里茨 | 7-6(3), 4-6, 6-2, 6-3 |\\n|  | 半决赛 | 扬尼克·辛纳 | 1-6, 2-6, 7-6(6), 3-6 |\\n\\n**2025年澳网展望**\\n\\n由于距离2025年澳网还有较长时间，现在预测德约科维奇的具体表现还为时过早。不过，我们可以基于以下因素进行一些展望：\\n\\n*   **年龄和身体状况：** 德约科维奇是一位非常注重身体保养的球员，但随着年龄增长，伤病和体能恢复可能会成为更大的挑战。他的身体状况将直接影响他在2025年澳网的竞争力。\\n*   **技术状态：** 德约科维奇的技术非常全面，但需要不断调整和适应新的趋势。他能否保持高水平的技术状态，并在2025年澳网之前进行有效的训练和调整，将至关重要。\\n*   **竞争对手：** 新一代年轻球员如阿尔卡拉斯、辛纳等人正在崛起，对德约科维奇的统治地位构成威胁。他在2025年澳网上面临的竞争将非常激烈。\\n*   **参赛意愿：** 德约科维奇是否决定参加2025年澳网，以及他对这项赛事的重视程度，也会影响他的备战和表现。\\n\\n**总之，如果德约科维奇能够保持健康、调整好状态，并积极备战，他仍然是2025年澳网冠军的有力争夺者。** 然而，他需要克服年龄、伤病和年轻一代球员的挑战，才能再次在墨尔本公园创造辉煌。\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-jsJSyBtrP8"
      },
      "source": [
        "## Summary\n",
        "\n",
        "The ReAct prompted Gemini model is grounded by external information sources and hence is less prone to hallucination. Furthermore, Thought-Action-Observation  traces generated by the model enhance human interpretability and trustworthiness by allowing users to witness the model's reasoning process for answering the user's query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmdNYTm5Lobz"
      },
      "source": [
        "## Next steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTiDOoTkLvH6"
      },
      "source": [
        "Head over to this [Streamlit app](https://mayochat.streamlit.app/) to interact with a ReAct prompted Gemini bot built with this code."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Search_Wikipedia_using_ReAct.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
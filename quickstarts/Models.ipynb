{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Lv3UtGCFH4"
      },
      "source": [
        "# Gemini API: List models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAJ9EGE2SoXm"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb\"><img src=\"https://github.com/google-gemini/cookbook/blob/main/images/colab_logo_32px.png?raw=1\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh9D-DvWSuqq"
      },
      "source": [
        "This notebook demonstrates how to list the models that are available for you to use in the Gemini API, and how to find details about a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i755jXzS5kLN"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "49H9jQPO_TJ9"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ol10W6Q_Y-s"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8PXsFZBQ_XA5"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Al4lFhNB22n"
      },
      "source": [
        "## List models\n",
        "\n",
        "Use `list_models()` to see what models are available. These models support `generateContent`, the main method used for prompting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3wE76b_gBn2k",
        "outputId": "307eb738-45b3-4a70-9163-483656dbb5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlguLt1yKET9"
      },
      "source": [
        "These models support `embedContent`, used for embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lQmlIpr5JHqz",
        "outputId": "667d24a0-98e7-408a-d9a7-add7b52ce2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "    # if \"flash\" in m.supported_generation_methods:\n",
        "      print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFJAyDD9QVrC"
      },
      "source": [
        "## Find details about a model\n",
        "\n",
        "You can see more details about a model, including the `input_token_limit` and `output_token_limit` as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BYYxVE4ZnoGy",
        "outputId": "5dec3e9d-9b38-4b9b-88eb-91919df6a82a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/gemini-2.0-flash',\n",
            "      base_model_id='',\n",
            "      version='2.0',\n",
            "      display_name='Gemini 2.0 Flash',\n",
            "      description='Gemini 2.0 Flash',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "    if m.name == \"models/gemini-2.0-flash\":\n",
        "        print(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00a56cb21953"
      },
      "source": [
        "## Get model\n",
        "\n",
        "Use `get_model()` to retrieve the specific details of a model. You can iterate over all available models using `list_models()`, but if you already know the model name you can retrieve it directly with `get_model()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6786759016dc",
        "outputId": "363be683-3315-4b6c-d498-533529d7d52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/aqa',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Model that performs Attributed Question Answering.',\n",
            "      description=('Model trained to return answers to questions that are grounded in provided '\n",
            "                   'sources, along with estimating answerable probability.'),\n",
            "      input_token_limit=7168,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateAnswer'],\n",
            "      temperature=0.2,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=40)\n"
          ]
        }
      ],
      "source": [
        "model_info = genai.get_model(\"models/aqa\")\n",
        "print(model_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq7i5FAwCe1v"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "* To learn how use a model for prompting, see the [Prompting](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb) quickstart.\n",
        "\n",
        "* To learn how use a model for embedding, see the [Embedding](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb) quickstart.\n",
        "\n",
        "* For more information on models, visit the [Gemini models](https://ai.google.dev/models/gemini) documentation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Models.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}